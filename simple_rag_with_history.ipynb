{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace, HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_chroma import Chroma\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\02-NextCloud\\github\\LangChain-Playground\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to C:\\Users\\piamp\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False,\n",
    "    repetition_penalty=1.03,\n",
    "    huggingfacehub_api_token=hf_token\n",
    ")\n",
    "llama = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_loader = CSVLoader(file_path=\"content/cofee.csv\",)\n",
    "data = csv_loader.load()\n",
    "markdown_loader = UnstructuredMarkdownLoader(\"content/api_plazos_compartidos.md\")\n",
    "data += markdown_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(\n",
    "    data,\n",
    "    embedding=HuggingFaceEmbeddings(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_template = \"\"\"\n",
    "Answer questions using the provided context only.\n",
    "\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages([(\"human\", message_template)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "historial = []\n",
    "\n",
    "def handle_message(message):\n",
    "    chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt\n",
    "    chained = chain.invoke(message)\n",
    "    historial.append(chained.to_messages()[0])\n",
    "    response = llama.invoke(historial)\n",
    "    historial.append(response)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content=\"\\nAnswer questions using the provided context only.\\n\\nhola\\n\\nContext:\\n[Document(metadata={'row': 286, 'source': 'content/cofee.csv'}, page_content='date: 2024-04-14\\\\ndatetime: 2024-04-14 12:29:06.877\\\\ncash_type: cash\\\\ncard: \\\\nmoney: 30.0\\\\ncoffee_name: Cortado'), Document(metadata={'row': 285, 'source': 'content/cofee.csv'}, page_content='date: 2024-04-14\\\\ndatetime: 2024-04-14 12:27:08.951\\\\ncash_type: cash\\\\ncard: \\\\nmoney: 30.0\\\\ncoffee_name: Cortado'), Document(metadata={'row': 83, 'source': 'content/cofee.csv'}, page_content='date: 2024-03-11\\\\ndatetime: 2024-03-11 11:24:51.565\\\\ncash_type: cash\\\\ncard: \\\\nmoney: 30.0\\\\ncoffee_name: Cortado'), Document(metadata={'row': 138, 'source': 'content/cofee.csv'}, page_content='date: 2024-03-20\\\\ndatetime: 2024-03-20 11:41:16.403\\\\ncash_type: card\\\\ncard: ANON-0000-0000-0012\\\\nmoney: 28.9\\\\ncoffee_name: Cortado'), Document(metadata={'row': 220, 'source': 'content/cofee.csv'}, page_content='date: 2024-04-03\\\\ndatetime: 2024-04-03 15:36:11.735\\\\ncash_type: cash\\\\ncard: \\\\nmoney: 30.0\\\\ncoffee_name: Cortado')]\\n\"), AIMessage(content=\"I'm ready to answer questions based on the provided context. Go ahead and ask away!\", response_metadata={'token_usage': ChatCompletionOutputUsage(completion_tokens=19, prompt_tokens=399, total_tokens=418), 'model': '', 'finish_reason': 'eos_token'}, id='run-34d9ba24-dde3-4ea2-9ec3-3ac20bb4f4cb-0'), HumanMessage(content=\"\\nAnswer questions using the provided context only.\\n\\nim martin\\n\\nContext:\\n[Document(metadata={'row': 175, 'source': 'content/cofee.csv'}, page_content='date: 2024-03-26\\\\ndatetime: 2024-03-26 11:11:47.335\\\\ncash_type: card\\\\ncard: ANON-0000-0000-0009\\\\nmoney: 28.9\\\\ncoffee_name: Cortado'), Document(metadata={'row': 274, 'source': 'content/cofee.csv'}, page_content='date: 2024-04-12\\\\ndatetime: 2024-04-12 19:38:23.189\\\\ncash_type: card\\\\ncard: ANON-0000-0000-0009\\\\nmoney: 28.9\\\\ncoffee_name: Cortado'), Document(metadata={'row': 127, 'source': 'content/cofee.csv'}, page_content='date: 2024-03-17\\\\ndatetime: 2024-03-17 12:55:26.065\\\\ncash_type: card\\\\ncard: ANON-0000-0000-0063\\\\nmoney: 28.9\\\\ncoffee_name: Cortado'), Document(metadata={'row': 52, 'source': 'content/cofee.csv'}, page_content='date: 2024-03-08\\\\ndatetime: 2024-03-08 10:34:41.283\\\\ncash_type: card\\\\ncard: ANON-0000-0000-0012\\\\nmoney: 28.9\\\\ncoffee_name: Cortado'), Document(metadata={'row': 138, 'source': 'content/cofee.csv'}, page_content='date: 2024-03-20\\\\ndatetime: 2024-03-20 11:41:16.403\\\\ncash_type: card\\\\ncard: ANON-0000-0000-0012\\\\nmoney: 28.9\\\\ncoffee_name: Cortado')]\\n\"), AIMessage(content=\"I'm ready to answer questions based on the provided context. Go ahead and ask away!\", response_metadata={'token_usage': ChatCompletionOutputUsage(completion_tokens=19, prompt_tokens=856, total_tokens=875), 'model': '', 'finish_reason': 'eos_token'}, id='run-f1653b4b-77e2-4a44-b1b1-956d6bec0cbb-0'), HumanMessage(content=\"\\nAnswer questions using the provided context only.\\n\\ncuantos cafees se vendieron en total\\n\\nContext:\\n[Document(metadata={'row': 739, 'source': 'content/cofee.csv'}, page_content='date: 2024-06-09\\\\ndatetime: 2024-06-09 11:04:41.306\\\\ncash_type: card\\\\ncard: ANON-0000-0000-0141\\\\nmoney: 27.92\\\\ncoffee_name: Cortado'), Document(metadata={'row': 876, 'source': 'content/cofee.csv'}, page_content='date: 2024-06-27\\\\ndatetime: 2024-06-27 16:11:48.000\\\\ncash_type: card\\\\ncard: ANON-0000-0000-0327\\\\nmoney: 27.92\\\\ncoffee_name: Cortado'), Document(metadata={'row': 779, 'source': 'content/cofee.csv'}, page_content='date: 2024-06-14\\\\ndatetime: 2024-06-14 07:46:13.238\\\\ncash_type: card\\\\ncard: ANON-0000-0000-0141\\\\nmoney: 27.92\\\\ncoffee_name: Cortado'), Document(metadata={'row': 486, 'source': 'content/cofee.csv'}, page_content='date: 2024-05-15\\\\ndatetime: 2024-05-15 14:39:44.367\\\\ncash_type: card\\\\ncard: ANON-0000-0000-0012\\\\nmoney: 27.92\\\\ncoffee_name: Cortado'), Document(metadata={'row': 586, 'source': 'content/cofee.csv'}, page_content='date: 2024-05-24\\\\ndatetime: 2024-05-24 18:18:36.698\\\\ncash_type: card\\\\ncard: ANON-0000-0000-0209\\\\nmoney: 27.92\\\\ncoffee_name: Cortado')]\\n\"), AIMessage(content=\"I don't see any records in the provided context.\", response_metadata={'token_usage': ChatCompletionOutputUsage(completion_tokens=12, prompt_tokens=1321, total_tokens=1333), 'model': '', 'finish_reason': 'eos_token'}, id='run-358565ed-9889-4605-9fd7-097ca7fdb1f1-0'), HumanMessage(content=\"\\nAnswer questions using the provided context only.\\n\\nwich is the cofee in row 1\\n\\nContext:\\n[Document(metadata={'row': 39, 'source': 'content/cofee.csv'}, page_content='date: 2024-03-05\\\\ndatetime: 2024-03-05 17:56:15.776\\\\ncash_type: card\\\\ncard: ANON-0000-0000-0028\\\\nmoney: 28.9\\\\ncoffee_name: Cortado'), Document(metadata={'row': 486, 'source': 'content/cofee.csv'}, page_content='date: 2024-05-15\\\\ndatetime: 2024-05-15 14:39:44.367\\\\ncash_type: card\\\\ncard: ANON-0000-0000-0012\\\\nmoney: 27.92\\\\ncoffee_name: Cortado'), Document(metadata={'row': 485, 'source': 'content/cofee.csv'}, page_content='date: 2024-05-15\\\\ndatetime: 2024-05-15 14:38:52.347\\\\ncash_type: card\\\\ncard: ANON-0000-0000-0169\\\\nmoney: 27.92\\\\ncoffee_name: Cortado'), Document(metadata={'row': 423, 'source': 'content/cofee.csv'}, page_content='date: 2024-05-07\\\\ndatetime: 2024-05-07 11:21:58.493\\\\ncash_type: card\\\\ncard: ANON-0000-0000-0141\\\\nmoney: 27.92\\\\ncoffee_name: Cortado'), Document(metadata={'row': 779, 'source': 'content/cofee.csv'}, page_content='date: 2024-06-14\\\\ndatetime: 2024-06-14 07:46:13.238\\\\ncash_type: card\\\\ncard: ANON-0000-0000-0141\\\\nmoney: 27.92\\\\ncoffee_name: Cortado')]\\n\")]\n",
      "Bot: The coffee in row 1 is Cortado.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    message = input(\"You: \")\n",
    "    if message == \"exit\":\n",
    "        break\n",
    "\n",
    "    response = handle_message(message)\n",
    "    print(\"Bot:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
